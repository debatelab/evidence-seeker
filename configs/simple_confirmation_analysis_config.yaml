# `config_version` is used internally to indicate and check 
# whether a config is compatible with the (current) code.
# (Currently hardset in `workflow.py`.)
config_version: 'v0.1'
description: |
  Erste Version einer Konfiguration für die EvidenceSeeker Boilerplate.
pipeline:
  system_prompt: &default_sp |
    You are a helpful assistant with outstanding expertise in critical thinking and logico-semantic analysis. You have a background in philosophy and experience in fact checking and debate analysis.
    You read instructions carefully and follow them precisely. You give concise and clear answers.
  simple_confirmation_analysis:
    timeout: 60
    verbose: False
    used_model_key: model_1
    workflow_events:
      freetext_confirmation_analysis_event:
        name: 'Freetext confirmation analysis'
        description: |
          Instruct the assistant to carry out free-text analysis of whether a document (text snippet)
          entails the claim in question.
        prompt_template: |
          Determine the relationship between the following two texts:

          <TEXT>{evidence_item}</TEXT>
          
          <HYPOTHESIS>{statement}</HYPOTHESIS>

          Does the TEXT entail, contradict, or neither entail nor contradict the HYPOTHESIS?

          Classify the relationship as one of the following:

          Entailment: The TEXT provides sufficient evidence to support the HYPOTHESIS.
          Contradiction: The TEXT provides evidence that contradicts the HYPOTHESIS.
          Neutral: The TEXT neither supports nor contradicts the HYPOTHESIS.

          Please discuss this question thoroughly before providing your final answer.
        system_prompt: *default_sp
      multiple_choice_confirmation_analysis_event:
        used_model_key: model_3
        name: 'Multiple choice confirmation analysis'
        description: |
          Instruct the assistant to decide whether the text confirms or disconfirms the claim.
        prompt_template: |
          Your task is to sum up the results of a rich textual entailment analysis.
          
          <TEXT>{evidence_item}</TEXT>
          
          <HYPOTHESIS>{statement}</HYPOTHESIS>
          
          Our previous analysis has yielded the following result:
          
          <RESULT>
          {freetext_confirmation_analysis_event}
          </RESULT>
          
          Please sum up this result by deciding which of the following choices is correct. Just answer with the label of the correct choice.
          
          (A) Entailment: The TEXT provides sufficient evidence to support the HYPOTHESIS.
          (B) Contradiction: The TEXT provides evidence that contradicts the HYPOTHESIS.
          (C) Neutral: The TEXT neither supports nor contradicts the HYPOTHESIS.
# Alternative:
#          (A) The TEXT entails (i.e., provides sufficient evidence to support) the HYPOTHESIS.
#          (B) The TEXT contradicts (i.e., provides evidence that contradicts) the HYPOTHESIS.
#          (C) Neutral: The TEXT neither supports nor contradicts the HYPOTHESIS.
        options: [(A, (B, (C]
        claim_option: (A
        regex_str: '(\(A)|(\(B)|(\(C)'
        system_prompt: *default_sp
models:
  model_1:
    name: "Llama-3.1-70B-Instruct"
    description: "NVIDEA NIM API (kostenpflichtig über DebateLab Account)"
    base_url: "https://huggingface.co/api/integrations/dgx/v1"
    model: "meta-llama/Llama-3.1-70B-Instruct"
    api_key_name: "kideku_toxicity_app_nim"
    backend_type: nim
    # TODO: pass values 
    max_tokens: 2048 # 2048
    temperature: 0.2
  model_2:
    name: "Mistral-7B-Instruct-v0.2"
    description: "HF inference API"
    base_url: "https://api-inference.huggingface.co/v1/"
    model: "mistralai/Mistral-7B-Instruct-v0.2"
    api_key_name: "HF_TOKEN_KIDEKU_INFERENCE"
    backend_type: openai
    # TODO: pass values 
    max_tokens: 1024
    temperature: 0.2
  model_3:
    name: "Llama-3.2-3B-Instruct"
    description: "HF dedicated endpoint (debatelab)"
    base_url: "https://dchi8b9swca6gxbe.eu-west-1.aws.endpoints.huggingface.cloud/v1/"
    model: "meta-llama/Llama-3.2-3B-Instruct"
    api_key_name: "token_debatelab_hf_endpoints"
    backend_type: tgi
    # TODO: pass values 
    max_tokens: 2048
    temperature: 0.2
  model_4:
    name: "Spätzle 8B"
    description: "Kriton@DebateLab"
    #base_url: "http://kriton.philosophie.kit.edu:8080/v1/chat/completions/"
    base_url: "http://kriton.philosophie.kit.edu:8080/v1/"
    model: "tgi"
    api_key: "no-key-required"
    backend_type: tgi
    # TODO: pass values 
    max_tokens: 2048
    temperature: 0.2
  

