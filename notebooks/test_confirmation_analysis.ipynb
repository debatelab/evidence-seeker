{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiating observation via Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "# %pip pip install arize-phoenix\n",
    "# %pip install llama-index-callbacks-arize-phoenix\n",
    "# observability\n",
    "import phoenix as px\n",
    "px.launch_app()\n",
    "\n",
    "import llama_index.core\n",
    "llama_index.core.set_global_handler(\"arize_phoenix\", endpoint=\"http://localhost:6006/v1/traces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirmation Analysis Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class 'evidence_seeker.confirmation_analysis.MultipleChoiceConfirmationAnalysisEvent'>\n",
      "<class 'evidence_seeker.confirmation_analysis.FreetextConfirmationAnalysisEvent'>\n",
      "../tmp/SimpleConfirmationAnalysisWorkflow.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "from evidence_seeker.confirmation_analysis import (\n",
    "    SimpleConfirmationAnalysisWorkflow\n",
    ")\n",
    "\n",
    "# create dir ../tmp if not exists\n",
    "os.makedirs(\"../tmp\", exist_ok=True)\n",
    "\n",
    "draw_all_possible_flows(\n",
    "    SimpleConfirmationAnalysisWorkflow, filename=\"../tmp/SimpleConfirmationAnalysisWorkflow.html\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidence_seeker.models import (\n",
    "    CheckedClaim,\n",
    "    Document\n",
    ")\n",
    "from evidence_seeker.confirmation_analysis import (\n",
    "    ConfirmationAnalyzer,\n",
    ")\n",
    "\n",
    "docs = [Document(text='There is high confidence that oxygen levels have \\ndropped in many regions since the mid 20th century and \\nthat the geographic range of many marine organisms has \\nchanged over the last two decades. \\n The amount of ocean warming observed since 1971 \\nwill likely at least double by 2100 under a low warming \\nscenario (SSP1-2.6) and will increase by 4‚Äì8 times under \\na high warming scenario (SSP5-8.5).  Stratification (virtually \\ncertain), acidification ( virtually certain ), deoxygenation \\n(high confidence ) and marine heatwave frequency ( high \\nconfidence) will continue to increase in the 21st century. \\n While there is low confidence in 20th century AMOC change, \\nit is very likely that AMOC will decline over the 21st century \\n(Figure TS.11).  {2.3, 3.5, 3.6, 4.3.2, 5.3, 7.2, 9.2, Box\\xa09.2, 12.4}\\nIt is virtually certain that the global ocean has warmed since at least \\n1971, representing about 90% of the increase in the global energy \\ninventory (Section TS.3.1).  The ocean is currently warming faster than \\nat any other time since at least the last deglacial transition (medium \\nconfidence), with warming extending to depths well below 2000 m \\n(very high confidence ).  It is extremely likely that human influence \\nwas the main driver of this recent ocean warming. ', uid='1f47ce98-4105-4ddc-98a9-c4956dab2000', metadata={'page_label': '74', 'file_name': 'IPCC_AR6_WGI_TS.pdf', 'author': 'IPCC Working Group I', 'original_text': 'While there is low confidence in 20th century AMOC change, \\nit is very likely that AMOC will decline over the 21st century \\n(Figure TS.11). '}),\n",
    " Document(text='Based on recent refined \\nanalyses of the available observations, there is high confidence  \\nthat it increased by 4.9 ¬± 1.5% from 1970‚Äì2018, which is about \\ntwice as much as assessed in SROCC, and will continue to increase \\nthroughout the 21st century at a rate depending on the emissions \\nscenario (virtually certain).  {2.3.3, 9.2.1}\\nIt is virtually certain that since 1950 near-surface high-salinity \\nregions have become more saline, while low-salinity regions have \\nbecome fresher, with medium confidence  that this is linked to an \\nintensification of the hydrological cycle (Box TS.6).  It is extremely \\nlikely that human influence has contributed to this salinity change \\nand that the large-scale pattern will grow in amplitude over the 21st \\ncentury (medium confidence).  {2.3.3, 3.5.2, 9.2.2, 12.4.8}\\nThe AMOC was relatively stable during the past 8000 years (medium \\nconfidence).  There is low confidence in the quantification of AMOC \\nchanges in the 20th century because of low agreement in quantitative \\nreconstructed and simulated trends, missing key processes in both \\nmodels and measurements used for formulating proxies, and new \\nmodel evaluations.  Direct observational records since the mid-2000s \\nare too short to determine the relative contributions of internal \\nvariability, natural forcing and anthropogenic forcing to AMOC \\nchange (high confidence).  An AMOC decline over the 21st century \\nis very likely for all SSP scenarios (Figure TS.11b); a possible abrupt \\ndecline is assessed further in Box TS.3. ', uid='6fcd6c0f-99a1-48e7-881f-f79758c54769', metadata={'page_label': '74', 'file_name': 'IPCC_AR6_WGI_TS.pdf', 'author': 'IPCC Working Group I', 'original_text': '{2.3.3, 3.5.2, 9.2.2, 12.4.8}\\nThe AMOC was relatively stable during the past 8000 years (medium \\nconfidence). '}),\n",
    " Document(text='{2.3.3, 3.5.2, 9.2.2, 12.4.8}\\nThe AMOC was relatively stable during the past 8000 years (medium \\nconfidence).  There is low confidence in the quantification of AMOC \\nchanges in the 20th century because of low agreement in quantitative \\nreconstructed and simulated trends, missing key processes in both \\nmodels and measurements used for formulating proxies, and new \\nmodel evaluations.  Direct observational records since the mid-2000s \\nare too short to determine the relative contributions of internal \\nvariability, natural forcing and anthropogenic forcing to AMOC \\nchange (high confidence).  An AMOC decline over the 21st century \\nis very likely for all SSP scenarios (Figure TS.11b); a possible abrupt \\ndecline is assessed further in Box TS.3.  {2.3.3, 3.5.4, 4.3.2, 8.6.1, \\n9.2.3, Cross-Chapter Box\\xa012.3}\\nThere is high confidence that many ocean currents will change in \\nthe 21st century in response to changes in wind stress.   There is low \\nconfidence in 21st century change of Southern Ocean circulation, \\ndespite high confidence  that it is sensitive to changes in wind \\npatterns and increased ice-shelf melt.  Western boundary currents \\nand subtropical gyres have shifted poleward since 1993 ( medium \\nconfidence). ', uid='f52c120f-ff9c-4893-822e-bfca72eaa9c6', metadata={'page_label': '74', 'file_name': 'IPCC_AR6_WGI_TS.pdf', 'author': 'IPCC Working Group I', 'original_text': 'An AMOC decline over the 21st century \\nis very likely for all SSP scenarios (Figure TS.11b); a possible abrupt \\ndecline is assessed further in Box TS.3. '}),\n",
    " Document(text='73\\nTechnical Summary\\nTS\\nBox TS.3 (continued)\\nWhile there is medium confidence  that the projected decline in the AMOC (Section TS.2.4) will not involve an abrupt collapse \\nbefore\\xa02100, such a collapse might be triggered by an unexpected meltwater influx from the Greenland Ice Sheet.  If an AMOC collapse \\nwere to occur, it would very likely cause abrupt shifts in the regional weather patterns and water cycle, such as a southward shift in the \\ntropical rain belt, and could result in weakening of the African and Asian monsoons, strengthening of Southern Hemisphere monsoons, \\nand drying in Europe.  (See also Boxes TS.9 and TS.13).  {4.7.2, 8.6.1, 9.2.3}\\nVery rare extremes and compound or concurrent events, such as the 2018 concurrent heatwaves across the Northern Hemisphere, are \\noften associated with large impacts.  The changing climate state is already altering the likelihood of extreme events, such as decadal \\ndroughts and extreme sea levels, and will continue to do so under future warming. ', uid='1f8242fe-50a2-45e2-bfda-986466f966d4', metadata={'page_label': '73', 'file_name': 'IPCC_AR6_WGI_TS.pdf', 'author': 'IPCC Working Group I', 'original_text': 'If an AMOC collapse \\nwere to occur, it would very likely cause abrupt shifts in the regional weather patterns and water cycle, such as a southward shift in the \\ntropical rain belt, and could result in weakening of the African and Asian monsoons, strengthening of Southern Hemisphere monsoons, \\nand drying in Europe. '}),\n",
    " Document(text='Some processes suspected of having tipping points, such as the Atlantic Meridional Overturning \\nCirculation (AMOC), have been found to often undergo recovery after temperature stabilization with a time delay ( low confidence). \\n However, substantial irreversibility is further substantiated for some cryosphere changes, ocean warming, sea level rise, and ocean \\nacidification.  {4.7.2, 5.3.3, 5.4.9, 9.2.2, 9.2.4, 9.4.1, 9.4.2, 9.6.3}\\nSome climate system components are slow to respond, such as the deep ocean overturning circulation and the ice sheets.  It is likely that \\nunder stabilization of global warming at 1.5¬∞C, 2.0¬∞C or 3.0¬∞C relative to 1850‚Äì1900, the AMOC will continue to weaken for several \\ndecades by about 15%, 20% and 30% of its strength and then recover to pre-decline values over several centuries (medium confidence). \\n At sustained warming levels between 2¬∞C and 3¬∞C, there is limited evidence that the Greenland and West Antarctic ice sheets will be lost \\nalmost completely and irreversibly over multiple millennia; both the probability of their complete loss and the rate of mass loss increases \\nwith higher surface temperatures ( high confidence).  At sustained warming levels between 3¬∞C and 5¬∞C, near-complete loss of the \\nGreenland Ice Sheet and complete loss of the West Antarctic Ice Sheet is projected to occur irreversibly over multiple millennia (medium \\nconfidence); with substantial parts or all of Wilkes Subglacial Basin in East Antarctica lost over multiple millennia (low confidence).  Early-\\nwarning signals of accelerated sea level rise from Antarctica could possibly be observed within the next few decades. ', uid='87697b86-aa91-4bdb-b02c-7dbd2af4dd9c', metadata={'page_label': '106', 'file_name': 'IPCC_AR6_WGI_TS.pdf', 'author': 'IPCC Working Group I', 'original_text': 'It is likely that \\nunder stabilization of global warming at 1.5¬∞C, 2.0¬∞C or 3.0¬∞C relative to 1850‚Äì1900, the AMOC will continue to weaken for several \\ndecades by about 15%, 20% and 30% of its strength and then recover to pre-decline values over several centuries (medium confidence). \\n'}),\n",
    " Document(text='{2.3.3, 9.2.1}\\nIt is virtually certain that since 1950 near-surface high-salinity \\nregions have become more saline, while low-salinity regions have \\nbecome fresher, with medium confidence  that this is linked to an \\nintensification of the hydrological cycle (Box TS.6).  It is extremely \\nlikely that human influence has contributed to this salinity change \\nand that the large-scale pattern will grow in amplitude over the 21st \\ncentury (medium confidence).  {2.3.3, 3.5.2, 9.2.2, 12.4.8}\\nThe AMOC was relatively stable during the past 8000 years (medium \\nconfidence).  There is low confidence in the quantification of AMOC \\nchanges in the 20th century because of low agreement in quantitative \\nreconstructed and simulated trends, missing key processes in both \\nmodels and measurements used for formulating proxies, and new \\nmodel evaluations.  Direct observational records since the mid-2000s \\nare too short to determine the relative contributions of internal \\nvariability, natural forcing and anthropogenic forcing to AMOC \\nchange (high confidence).  An AMOC decline over the 21st century \\nis very likely for all SSP scenarios (Figure TS.11b); a possible abrupt \\ndecline is assessed further in Box TS.3.  {2.3.3, 3.5.4, 4.3.2, 8.6.1, \\n9.2.3, Cross-Chapter Box\\xa012.3}\\nThere is high confidence that many ocean currents will change in \\nthe 21st century in response to changes in wind stress.  ', uid='abaed8de-7f35-40d8-bc9d-2a6a8e543586', metadata={'page_label': '74', 'file_name': 'IPCC_AR6_WGI_TS.pdf', 'author': 'IPCC Working Group I', 'original_text': 'There is low confidence in the quantification of AMOC \\nchanges in the 20th century because of low agreement in quantitative \\nreconstructed and simulated trends, missing key processes in both \\nmodels and measurements used for formulating proxies, and new \\nmodel evaluations. '}),\n",
    " Document(text='Models that exhibit such tipping points are characterized by abrupt changes once the threshold is crossed, and even \\na return to pre-threshold surface temperatures or to atmospheric carbon dioxide concentrations does not guarantee \\nthat the tipping elements return to their pre-threshold state.  Monitoring and early warning systems are being put into \\nplace to observe tipping elements in the climate system.  {1.3, 1.4.4, 1.5, 4.3.2, Table\\xa04.10, 5.3.4, 5.4.9, 7.5.3, 9.2.2, \\n9.2.4, 9.4.1, 9.4.2, 9.6.3, Cross-chapter Box\\xa012.1}\\nUnderstanding of multi-decadal reversibility (i.e., the system returns to the previous climate state within multiple decades after \\nthe radiative forcing is removed) has improved since AR5 for many atmospheric, land surface and sea ice climate metrics following \\nsea surface temperature recovery.  Some processes suspected of having tipping points, such as the Atlantic Meridional Overturning \\nCirculation (AMOC), have been found to often undergo recovery after temperature stabilization with a time delay ( low confidence). \\n However, substantial irreversibility is further substantiated for some cryosphere changes, ocean warming, sea level rise, and ocean \\nacidification.  {4.7.2, 5.3.3, 5.4.9, 9.2.2, 9.2.4, 9.4.1, 9.4.2, 9.6.3}\\nSome climate system components are slow to respond, such as the deep ocean overturning circulation and the ice sheets.  It is likely that \\nunder stabilization of global warming at 1.5¬∞C, 2.0¬∞C or 3.0¬∞C relative to 1850‚Äì1900, the AMOC will continue to weaken for several \\ndecades by about 15%, 20% and 30% of its strength and then recover to pre-decline values over several centuries (medium confidence). \\n', uid='64dce431-7e8d-46cd-9dd8-dc7e2ac18443', metadata={'page_label': '106', 'file_name': 'IPCC_AR6_WGI_TS.pdf', 'author': 'IPCC Working Group I', 'original_text': 'Some processes suspected of having tipping points, such as the Atlantic Meridional Overturning \\nCirculation (AMOC), have been found to often undergo recovery after temperature stabilization with a time delay ( low confidence). \\n'}),\n",
    " Document(text='72\\nTechnical Summary\\nTS\\nBox TS.3 | Low-likelihood, High-warming Storylines\\nFuture global warming exceeding the assessed very likely range cannot be ruled out and is potentially associated \\nwith the highest risks for society and ecosystems.  Such low-likelihood, high-warming storylines tend to exhibit \\nsubstantially greater changes in the intensity of regional drying and wetting than the multi-model mean.  Even at \\nlevels of warming within the very likely range, global and regional low-likelihood outcomes might occur, such as large \\nprecipitation changes, additional sea level rise associated with collapsing ice sheets (see Box TS.4), or abrupt ocean \\ncirculation changes.  While there is medium confidence that the Atlantic Meridional Overturning Circulation (AMOC) \\nwill not experience an abrupt collapse before 2100, if it were to occur, it would very likely cause abrupt shifts in \\nregional weather patterns and water cycle.  The probability of these low-likelihood outcomes increases with higher \\nglobal warming levels.  If the real-world climate sensitivity lies at the high end of the assessed range, then global \\nand regional changes substantially outside the very likely range projections occur for a given emissions scenario. \\n With increasing global warming, some very rare extremes and some compound events (multivariate or concurrent \\nextremes) with low likelihood in past and current climate will become more frequent, and there is a\\xa0higher chance \\nthat events unprecedented in the observational record occur ( high confidence). ', uid='d7162beb-25d2-4653-aecd-2734bfd39693', metadata={'page_label': '72', 'file_name': 'IPCC_AR6_WGI_TS.pdf', 'author': 'IPCC Working Group I', 'original_text': 'While there is medium confidence that the Atlantic Meridional Overturning Circulation (AMOC) \\nwill not experience an abrupt collapse before 2100, if it were to occur, it would very likely cause abrupt shifts in \\nregional weather patterns and water cycle. '})]\n",
    "\n",
    "claim = CheckedClaim(\n",
    "    text=\"The AMOC is slowing down\",\n",
    "    negation=\"The AMOC is not changing\",\n",
    "    uid=\"123\",\n",
    "    documents=docs\n",
    ")\n",
    "evidence_item = docs[0].text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running `ConfirmationAnalyzer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1f47ce98-4105-4ddc-98a9-c4956dab2000': 0.9366311468505643, '6fcd6c0f-99a1-48e7-881f-f79758c54769': 0.5378353475397207, 'f52c120f-ff9c-4893-822e-bfca72eaa9c6': 0.3276655653091819, '1f8242fe-50a2-45e2-bfda-986466f966d4': 0.40502036963125476, '87697b86-aa91-4bdb-b02c-7dbd2af4dd9c': 0.2906046993400315, 'abaed8de-7f35-40d8-bc9d-2a6a8e543586': 0.2080703532156991, '64dce431-7e8d-46cd-9dd8-dc7e2ac18443': 0.7073955196710597, 'd7162beb-25d2-4653-aecd-2734bfd39693': 0.6922158945091185}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# so far, only the dummy implementation is available\n",
    "confirmation_analyzer = ConfirmationAnalyzer()\n",
    "checked_claim = await confirmation_analyzer(claim=claim) \n",
    "print(checked_claim.confirmation_by_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the workflow directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from ../configs/simple_confirmation_analysis_config.yaml\n",
      "Used api key name: kideku_toxicity_app_nim\n",
      "Instantiating OpenAILike model (model: meta-llama/Llama-3.1-70B-Instruct,base_url: https://huggingface.co/api/integrations/dgx/v1).\n",
      "Confirmation analysis.\n",
      "Using workflow model: model_1 for freetext_confirmation_analysis_event\n",
      "Confirmation analysis.\n",
      "Using workflow model: model_1 for freetext_confirmation_analysis_event\n",
      "Used regex in multiple_choice_confirmation_analysis_event: [AB]\n",
      "Using event specific model: model_3 for multiple_choice_confirmation_analysis_event\n",
      "Used api key name: token_debatelab_hf_endpoints\n",
      "Instantiating OpenAILike model (model: meta-llama/Llama-3.2-3B-Instruct,base_url: https://dchi8b9swca6gxbe.eu-west-1.aws.endpoints.huggingface.cloud/v1/).\n",
      "Using event specific model: model_3 for multiple_choice_confirmation_analysis_event\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.941951356646046 seconds as it raised InternalServerError: Error code: 503 - {'error': '503 Service Unavailable'}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.6307064282927775 seconds as it raised InternalServerError: Error code: 503 - {'error': '503 Service Unavailable'}.\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503 - {'error': '503 Service Unavailable'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m config_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../configs/simple_confirmation_analysis_config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m     12\u001b[0m pw \u001b[38;5;241m=\u001b[39m SimpleConfirmationAnalysisWorkflow(config_file\u001b[38;5;241m=\u001b[39mconfig_file)\n\u001b[0;32m---> 14\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m pw\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m     15\u001b[0m     clarified_claim\u001b[38;5;241m=\u001b[39mclaim,\n\u001b[1;32m     16\u001b[0m     evidence_item\u001b[38;5;241m=\u001b[39mevidence_item\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m pprint(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/llama_index/core/workflow/workflow.py:378\u001b[0m, in \u001b[0;36mWorkflow.run.<locals>._run_workflow\u001b[0;34m()\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_raised:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# cancel the stream\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mwrite_event_to_stream(StopEvent())\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_raised\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m we_done:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;66;03m# cancel the stream\u001b[39;00m\n\u001b[1;32m    382\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mwrite_event_to_stream(StopEvent())\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/llama_index/core/workflow/workflow.py:233\u001b[0m, in \u001b[0;36mWorkflow._start.<locals>._task\u001b[0;34m(name, queue, step, config)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mretry_policy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     delay \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mretry_policy\u001b[38;5;241m.\u001b[39mnext(\n\u001b[1;32m    236\u001b[0m         retry_start_at \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mtime(), attempts, e\n\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m delay \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;66;03m# We're done retrying\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/llama_index/core/workflow/workflow.py:229\u001b[0m, in \u001b[0;36mWorkflow._start.<locals>._task\u001b[0;34m(name, queue, step, config)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m         new_ev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m instrumented_step(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# exit the retrying loop\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[1;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    355\u001b[0m )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/Nextcloud/Documents/mindmaps/mind/projects/kideku/code/evidence-seeker/src/evidence_seeker/confirmation_analysis.py:139\u001b[0m, in \u001b[0;36mSimpleConfirmationAnalysisWorkflow.collect_freetext_analyses\u001b[0;34m(self, ctx, ev)\u001b[0m\n\u001b[1;32m    126\u001b[0m log_msg(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsed regex in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mev\u001b[38;5;241m.\u001b[39mevent_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregex_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# multiple choice prompt\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# request_dict = await self._prompt_step(\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m#     ctx=ctx,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m#     **request_dict\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint_prompt_step(\n\u001b[1;32m    140\u001b[0m     ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    141\u001b[0m     ev\u001b[38;5;241m=\u001b[39mcollected_events[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    142\u001b[0m     regex_str\u001b[38;5;241m=\u001b[39mregex_str,\n\u001b[1;32m    143\u001b[0m     request_dict\u001b[38;5;241m=\u001b[39mrequest_dict,\n\u001b[1;32m    144\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    147\u001b[0m     },\n\u001b[1;32m    148\u001b[0m     full_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_dict\n\u001b[1;32m    150\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# calculate the confirmation score\u001b[39;00m\n\u001b[1;32m    152\u001b[0m options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkflow_key][\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkflow_events\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m     ][ev\u001b[38;5;241m.\u001b[39mevent_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Nextcloud/Documents/mindmaps/mind/projects/kideku/code/evidence-seeker/src/evidence_seeker/workflow.py:312\u001b[0m, in \u001b[0;36mEvidenceSeekerWorkflow._constraint_prompt_step\u001b[0;34m(self, ctx, ev, json_schema, output_cls, regex_str, append_input, request_dict, model_kwargs, full_response, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecify a JSON schema or a regex expression for\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstraint decoding with a TGI.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         )\n\u001b[1;32m    308\u001b[0m     response_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m json_schema \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregex\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: json_schema \u001b[38;5;28;01mif\u001b[39;00m json_schema \u001b[38;5;28;01melse\u001b[39;00m regex_str\n\u001b[1;32m    311\u001b[0m     }\n\u001b[0;32m--> 312\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m llm\u001b[38;5;241m.\u001b[39machat(\n\u001b[1;32m    313\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    314\u001b[0m         response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[1;32m    316\u001b[0m     )\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# default: Using the llama-index interface for structured output\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# see: https://docs.llamaindex.ai/en/stable/understanding/extraction/\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[1;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    355\u001b[0m )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/llama_index/llms/openai_like/base.py:158\u001b[0m, in \u001b[0;36mOpenAILike.achat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     completion_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macomplete(prompt, formatted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion_response_to_chat_response(completion_response)\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39machat(messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[1;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    355\u001b[0m )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/llama_index/core/llms/callbacks.py:75\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_async_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m     67\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m     68\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     },\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m f(_self, messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     77\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m     78\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m     79\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m     80\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m     81\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/llama_index/llms/openai/base.py:627\u001b[0m, in \u001b[0;36mOpenAI.achat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     achat_fn \u001b[38;5;241m=\u001b[39m acompletion_to_chat_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acomplete)\n\u001b[0;32m--> 627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m achat_fn(messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/tenacity/asyncio/__init__.py:189\u001b[0m, in \u001b[0;36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    188\u001b[0m async_wrapped\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m copy(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/tenacity/asyncio/__init__.py:111\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/tenacity/asyncio/__init__.py:153\u001b[0m, in \u001b[0;36mAsyncRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/tenacity/_utils.py:99\u001b[0m, in \u001b[0;36mwrap_to_async_func.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/tenacity/__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/tenacity/__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/tenacity/asyncio/__init__.py:114\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/llama_index/llms/openai/base.py:674\u001b[0m, in \u001b[0;36mOpenAI._achat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(messages, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreuse_client:\n\u001b[0;32m--> 674\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m aclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    675\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessage_dicts, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m aclient:\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/openai/resources/chat/completions.py:1633\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m AsyncStream[ChatCompletionChunk]:\n\u001b[1;32m   1632\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   1634\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1635\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[1;32m   1636\u001b[0m             {\n\u001b[1;32m   1637\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   1638\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   1639\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m   1640\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   1641\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m   1642\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m   1643\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m   1644\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m   1645\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m   1646\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m   1647\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m   1648\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m   1649\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m   1650\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m   1651\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m   1652\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m   1653\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m   1654\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m   1655\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m   1656\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m   1657\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   1658\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   1659\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   1660\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   1661\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   1662\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   1663\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   1664\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   1665\u001b[0m             },\n\u001b[1;32m   1666\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m   1667\u001b[0m         ),\n\u001b[1;32m   1668\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   1669\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1670\u001b[0m         ),\n\u001b[1;32m   1671\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m   1672\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1673\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[1;32m   1674\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/openai/_base_client.py:1838\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1824\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1825\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1826\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1834\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m   1835\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1836\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1837\u001b[0m     )\n\u001b[0;32m-> 1838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/openai/_base_client.py:1532\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1533\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1534\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1535\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1536\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1537\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1538\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/openai/_base_client.py:1618\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maclose()\n\u001b[0;32m-> 1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m   1619\u001b[0m         input_options,\n\u001b[1;32m   1620\u001b[0m         cast_to,\n\u001b[1;32m   1621\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1622\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1623\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1624\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1625\u001b[0m     )\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/openai/_base_client.py:1665\u001b[0m, in \u001b[0;36mAsyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1661\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1666\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1667\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1668\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1669\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1670\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1671\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/openai/_base_client.py:1618\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maclose()\n\u001b[0;32m-> 1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m   1619\u001b[0m         input_options,\n\u001b[1;32m   1620\u001b[0m         cast_to,\n\u001b[1;32m   1621\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1622\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1623\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1624\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1625\u001b[0m     )\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/openai/_base_client.py:1665\u001b[0m, in \u001b[0;36mAsyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1661\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1666\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1667\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1668\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1669\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1670\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1671\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/openai/_base_client.py:1618\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maclose()\n\u001b[0;32m-> 1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m   1619\u001b[0m         input_options,\n\u001b[1;32m   1620\u001b[0m         cast_to,\n\u001b[1;32m   1621\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1622\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1623\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1624\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1625\u001b[0m     )\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/openai/_base_client.py:1665\u001b[0m, in \u001b[0;36mAsyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1661\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1666\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1667\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1668\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1669\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1670\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1671\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/py-3.10-llm/lib/python3.10/site-packages/openai/_base_client.py:1633\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[1;32m   1630\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maread()\n\u001b[1;32m   1632\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1633\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1636\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1637\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1641\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1642\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 503 - {'error': '503 Service Unavailable'}"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "from evidence_seeker.confirmation_analysis import (\n",
    "    SimpleConfirmationAnalysisWorkflow\n",
    ")\n",
    "from evidence_seeker.backend import get_openai_llm\n",
    "\n",
    "\n",
    "config_file = \"../configs/simple_confirmation_analysis_config.yaml\" \n",
    "\n",
    "pw = SimpleConfirmationAnalysisWorkflow(config_file=config_file)\n",
    "\n",
    "result = await pw.run(\n",
    "    clarified_claim=claim,\n",
    "    evidence_item=evidence_item\n",
    ")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evidence-seeker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
